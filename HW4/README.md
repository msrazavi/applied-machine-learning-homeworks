# HW4: Gradient Descent Optimization

This project explores fundamental optimization techniques used to train machine learning models.

## Project Overview
**Gradient Descent for Minimizing a 3-D Function**

Gradient descent is a fundamental optimization technique widely used in machine learning and numerical analysis. In this project, I implemented the Gradient Descent Algorithm in Python to find the minimum of a two-variable function $f(x, y)$.

**Key steps performed:**
1. Defined a differentiable function with a known minimum.
2. Implemented gradient descent to iteratively approach the minimum.
3. Experimented with different **learning rates** and **initial points**.
4. Visualized the optimization path using **3D surface plots** and **2D contour plots**.

## Assignment Description
You can view the original full assignment description and requirements provided by the professor here:
> [**View Original Problem Statement (GitHub)**](https://github.com/hhomaei/aml/blob/main/Chapter-5-Optimization/HW/description.ipynb)

## Key Concepts
- Optimization Algorithms
- Partial Derivatives
- 3D Visualization
